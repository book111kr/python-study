{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8afe3b",
   "metadata": {},
   "source": [
    "# 영상의 이진화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b77f3",
   "metadata": {},
   "source": [
    "## 영상의 이진화\n",
    "- 영상의 픽셀 값을 0 또는 255(1)로 만드는 연산\n",
    "    - 배경(background) vs. 객체(object)\n",
    "    - 관심 영역 vs. 비관심 영역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6502c5",
   "metadata": {},
   "source": [
    "## 그레이 이미지의 이진화\n",
    "- T : 임계값,문턱치,threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f2af5",
   "metadata": {},
   "source": [
    "## threshold 함수\n",
    "- cv2.threshold(src, thresh, maxval, type, dst=None) -> retval, dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3605b264",
   "metadata": {},
   "source": [
    "- src : 입력 영상. 다채널, 8비트 또는 32비트 실수형.\n",
    "- thresh : 사용자 지정 임계값\n",
    "- maxval : cv2.THRESH_BINARY 또는 cv2.THRESH_BINARY_INV 방법 사용 시 최댓값. \n",
    "- type : cv2.THRESH_ 로 시작하는 플래그. 임계값 함수 동작 지정 또는 자동 임계값 결정 방법 지정\n",
    "- retval : 사용된 임계값\n",
    "- dst : 출력 영상. src와 동일 크기, 동일 타입, 같은 채널 수."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afa7bb",
   "metadata": {},
   "source": [
    "## threshold 의 type\n",
    "- cv2.threshold() 함수 동작 타입"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77360ade",
   "metadata": {},
   "source": [
    "## 이진화 동작\n",
    "src = cv2.imread('cells.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, dst1 = cv2.threshold(src, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "_, dst2 = cv2.threshold(src, 210, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17aaea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('cells.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "_, dst1 = cv2.threshold(src, 100, 255, cv2.THRESH_BINARY)\n",
    "_, dst2 = cv2.threshold(src, 210, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst1', dst1)\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315bcc7",
   "metadata": {},
   "source": [
    "## Otsu 이진화 결과\n",
    "src = cv2.imread('rice.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "print(\"otsu's threshold:\", th) # th결과값 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caf5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otsu's threshold: 131.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('rice.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "print(\"otsu's threshold:\", th) # 131\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789d7c0",
   "metadata": {},
   "source": [
    "# 지역 이진화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bb669",
   "metadata": {},
   "source": [
    "## 균일하지 않은 조명에서 일괄적인 threshold 적용은 문제가 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10f0ed",
   "metadata": {},
   "source": [
    "## 많이 사용하는 방법은 분할시켝서 각각 이진화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c4793",
   "metadata": {},
   "source": [
    "## 적응형 이진화 함수\n",
    "- cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C, dst=None) -> dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279654c",
   "metadata": {},
   "source": [
    "- src : 입력 영상. 다채널, 8비트 또는 32비트 실수형.\n",
    "- maxValue : 임계값 함수 최댓값. 보통 255.\n",
    "- adaptiveMethod : 블록 평균 계산 방법 지정. cv2.ADAPTIVE_THRESH_MEAN_C는 산술 평균, cv2.ADAPTIVE_THRESH_GAUSSIAN_C는 가우시안 가중치 평균\n",
    "- thresholdType : cv2.THRESH_BINARY 또는 cv2.THRESH_BINARY_INV 지정\n",
    "- blockSize : 블록 크기. 3 이상의 홀수.\n",
    "- C : 출력 영상. src와 동일 크기, 동일 타입, 같은 채널 수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "bsize = 201\n",
    "dst = cv2.adaptiveThreshold(src, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, bsize, 5)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.namedWindow('dst')\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db996313",
   "metadata": {},
   "source": [
    "# 픽셀 라벨링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b0ece",
   "metadata": {},
   "source": [
    "## 라벨링\n",
    "\n",
    "### 레이블링이란?\n",
    "- 동일 객체에 속한 모든 픽셀에 고유한 번호를 매기는 작업\n",
    "- 일반적으로 이진 영상에서 수행\n",
    "- OpenCV에는 3.x버전부터 최신 논문 기반의 레이블링 알고리즘 함수를 제공\n",
    "- Connected component labeling\n",
    "\n",
    "### 픽셀의 연결 관계\n",
    "- 4-이웃 연결 관계(4-neightbor connectivity)\n",
    "- 8-이웃 연결 관계(8-neightbor connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f3062",
   "metadata": {},
   "source": [
    "## 라벨링 함수\n",
    "- cv2.connectedComponents(image, labels=None, connectivity=None,\n",
    "                          ltype=None) -> retval, lables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6adaad",
   "metadata": {},
   "source": [
    "- image : 8비트 1채널 영상\n",
    "- labels : 레이블 맵 행렬. 입력 영상과 같은 크기.numpy.ndarray.\n",
    "- connectivity : 4 또는 8. 기본값은 8.\n",
    "- ltype : labels 행렬 타입. cv2.CV_32S 또는 cv2.CV_16S. 기본값은 cv2.CV_32S.\n",
    "- retval : 객체 개수. N을 반환하면 [0,N-1]의 레이블이 존재하며, 0은 배경을 의미.(실제 흰색 객체 개수는 N-1개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbdc7f6",
   "metadata": {},
   "source": [
    "## 정보를 보다 많이 반환하는 함수\n",
    "- cv2.connectedComponentsWithStats(image, labels=None, stats=None,\n",
    "                         centroids=None, connectivity=None, ltype=None) \n",
    "                         -> retval, labels, stats, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a174e4",
   "metadata": {},
   "source": [
    "- image : 8비트 1채널 영상\n",
    "- labels : 레이블 맵 행렬. 입력 영상과 같은 크기.numpy.ndarray.\n",
    "- stats : 각 객체의 바운딩 박스, 픽셀 개수 정보를 담은 행렬.numpy.ndarray.shape(N,5),dtype=numpy.int32.\n",
    "- centroids : 각 객체의 무게 중심 위치 정보를 담은 행렬.numpy.ndarray.shape(N,2),dtype=numpy.float64.\n",
    "- ltype : labels 행렬 타입. cv2.CV_32S 또는 cv2.CV_16S. 기본값은 cv2.CV_32S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815900b",
   "metadata": {},
   "source": [
    "## 결과\n",
    "### cv2.connectedComponentsWithStats()함수 수행 결과 예\n",
    "    \n",
    "    - retval, labels, stats, centroids = cv2.connectedComponentsWithStats(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0be7399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sep:\n",
      "[[0 0 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 1 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 1 1 1 0]\n",
      " [0 0 1 1 0 0 1 0]\n",
      " [0 0 1 1 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "cnt: 4\n",
      "labels:\n",
      "[[0 0 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 2 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 3 3 0]\n",
      " [0 0 0 3 3 3 3 0]\n",
      " [0 0 3 3 0 0 3 0]\n",
      " [0 0 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "mat = np.array([\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 1, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]], np.uint8)\n",
    "\n",
    "cnt, labels = cv2.connectedComponents(mat)\n",
    "\n",
    "print('sep:', mat, sep='\\n')\n",
    "print('cnt:', cnt)\n",
    "print('labels:', labels, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356c97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('keyboard.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in range(1, cnt):\n",
    "    (x, y, w, h, area) = stats[i]\n",
    "\n",
    "    if area < 20:\n",
    "        continue\n",
    "    \n",
    "    cv2.rectangle(dst, (x, y, w, h), (0, 255, 255))\n",
    "    cv2.putText(dst, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "    \n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df8a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외곽선 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf1bc0",
   "metadata": {},
   "source": [
    "## 외곽선 검출 함수\n",
    "- cv2.findContours(image, mode, method, contours=None, hierarchy=None,\n",
    "                   offset=None) -> contours, hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2cb5f",
   "metadata": {},
   "source": [
    "- image : 8비트 1채널 영상\n",
    "- mode : 외곽선 검출 모드.cv2.RETR_로 시작하는 상수.\n",
    "- method : 외곽선 근사화 방법.cv2.CHAIN_APPROX_로 시작하는 상수.\n",
    "- contours : 검출된 외곽선 좌표.numpy.ndarray로 구성된 리스트. len(contours)=전체 외곽선 개수(N).\n",
    "- hierarchy : 외곽선 계층 정보.numpy.ndarray.shape=(1,N,4).dtype=numpy.int32.hierarchy[0,i,0]~hierarchy[0,i,3]이 순서대로 next,prev,child,parent외곽선 인덱스를 가리킴. 해당 외곽선이 없으면 -1.\n",
    "- offset : 좌표 값 이동 옵셋. 기본값은 (0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b795ee",
   "metadata": {},
   "source": [
    "## 외곽선 검출 함수\n",
    "- cv2.findContours(image, contours, contoursIdx, color, thickness=None, lineType=None, hierarchy=None,\n",
    "                   maxLevel=None, offset=None) -> image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea07e9e",
   "metadata": {},
   "source": [
    "- image : 8비트 1채널 영상\n",
    "- contours : (cv2.findContours()함수로 구한) 외곽선 좌표 정보\n",
    "- contoursIdx : 외곽선 인덱스. 음수(-1)를 지정하면 모든 외곽선을 그린다\n",
    "- color : 외곽선 색상\n",
    "- thickness : 외곽선 두께.thinkness<0이면 내부를 채운다\n",
    "- lineType : LINE_4, LINE_8, LINE_AA중 하나 지정\n",
    "- hierarchy : 외곽선 계층 정보.\n",
    "- maxLevel : 그리기를 수행할 최대 외곽선 레벨.maxLevel=0 이면 contourldx로 지정된 외곽선만 그린다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67b2d5",
   "metadata": {},
   "source": [
    "## 외곽선 검출 예제\n",
    "src = cv2.imread('contours.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "contours, hier = cv2.findContours(src, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "while idx >= 0:\n",
    "    \n",
    "        c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        cv2.drawContours(dst, contours, idx, c, 2, cv2.LINE_8, hier)\n",
    "        idx = hier[0, idx, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792063ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "src = cv2.imread('contours.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "contours, hier = cv2.findContours(src, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "while idx >= 0:\n",
    "    c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    cv2.drawContours(dst, contours, idx, c, 2, cv2.LINE_8, hier)\n",
    "    idx = hier[0, idx, 0]\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba5960",
   "metadata": {},
   "source": [
    "## 계층 정보 없는 외곽선\n",
    "\n",
    "src = cv2.imread('milkdrop.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "contours, _ = cv2.findContours(src_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "dst = np.zeros((h, w, 3), np.uint8)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "\n",
    "    c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    cv2.drawContours(dst, contours, i, c, 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23f0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('milkdrop.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "contours, _ = cv2.findContours(src_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "dst = np.zeros((h, w, 3), np.uint8)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    c = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    cv2.drawContours(dst, contours, i, c, 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c71774",
   "metadata": {},
   "source": [
    "## 외곽선 관련 함수\n",
    "- cv2.arcLength() : 외곽선 길이 반환\n",
    "- cv2.contourArea() : 외곽선이 감싸는 영역의 면적을 반환\n",
    "- cv2.boundingRect() : 주어진 점을 감싸는 최소 크기 사각형(바운딩 박스)반환\n",
    "- cv2.minEnclosingCircle() : 주어진 점을 감싸는 최소 크기 원을 반환\n",
    "- cv2.minAreaRect() : 주어진 점을 감싸는 최소 크기 회전된 사각형을 반환\n",
    "- cv2.minEnclosingTriangle() : 주어진 점을 감싸는 최소 크기 삼각형을 반환\n",
    "- cv2.approxPolyDP() : 외곽선을 근사화(단순화)\n",
    "- cv2.fitEllipse() : 주어진 점에 적합한 타원을 반환\n",
    "- cv2.fitLine() : 주어진 점에 적합한 직선을 반환\n",
    "- cv2.isContourConvex() : 컨벡스인지를 검사\n",
    "- cv2.convexHull() : 주어진 점으로부터 컨벡스 헐을 반환\n",
    "- cv2.convexityDefects() : 주어진 점과 컨벡스 헐로부터 컨벡스 디펙트를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7fad9",
   "metadata": {},
   "source": [
    "## 외곽선 길이 구하기\n",
    "- cv2.arcLength(curve, closed) -> retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954657fe",
   "metadata": {},
   "source": [
    "- curve : 외곽선 좌표.numpy.ndarray.shape=(K,1,2)\n",
    "- closed : True이면 폐곡선으로 간주\n",
    "- retval : 외곽선 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3326f",
   "metadata": {},
   "source": [
    "## 면적 구하기\n",
    "- cv2.contourArea(contour, oriented=None) -> retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593dcf8",
   "metadata": {},
   "source": [
    "- contour : 외곽선 좌표.numpy.ndarray.shape=(K,1,2)\n",
    "- oriented : True이면 외곽선 진행 방향에 따라 부호 있는 면적을 반환.\n",
    "- retval : 외곽선으로 구성된 영역의 면적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8c903",
   "metadata": {},
   "source": [
    "## 바운딩 박스 구하기\n",
    "- cv2.boundingRect(array) -> retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64619fa0",
   "metadata": {},
   "source": [
    "- array : 외곽선 좌표.numpy.ndarray.shape=(K,1,2)\n",
    "- retval : 사각형 정보.(x,y,w,h)튜플."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532c1a5",
   "metadata": {},
   "source": [
    "## 바운딩 서클 구하기\n",
    "- cv2.minEnclosingCircle(points) -> center, radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a87bc8",
   "metadata": {},
   "source": [
    "- point : 외곽선 좌표.numpy.ndarray.shape=(K,1,2)\n",
    "- center : 바운딩 서클 중심 좌표. (x,y)튜플.\n",
    "-radius : 바운딩 서클 반지름.실수."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61781cb3",
   "metadata": {},
   "source": [
    "## 외곽선 근사화\n",
    "- cv2.approxPolyDP(curve, epsilon, closed, approxCurve=None) -> approxCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc80907",
   "metadata": {},
   "source": [
    "- curve : 입력 곡선 좌표.numpy.ndarray.shape=(K,1,2)\n",
    "- epsilon : 근사화 정밀도 조절. 입력 곡선과 근사화 곡선 간의 최대 거리.\n",
    "- closed : True를 전달하면 폐곡선으로 인식\n",
    "- approxCurve : 근사화된 곡선 좌표.numpy.ndarray.shape=(K',1,2)\n",
    "- 참고사항\n",
    "    - 더글라스-포이커 알고리즘(Douglas-Peucker algorithm)[Wiki]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8e5ce",
   "metadata": {},
   "source": [
    "## 컨벡스 검사\n",
    "- cv2.isContourConvex(contour) -> retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f5726",
   "metadata": {},
   "source": [
    "- contour : 입력 곡선 좌표.numpy.ndarray.shape=(k,1,2)\n",
    "- retval : 컨벡스이면 True, 아니면 False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29484c95",
   "metadata": {},
   "source": [
    "## 다각형 검출해보기\n",
    "### 다각형 판별 프로그램\n",
    "    - 다양한 다각형 객체 영상에서 삼각형, 사각형, 원 찾기\n",
    "### 구현 순서\n",
    "    1. 이진화\n",
    "    2. 외곽선 찾기\n",
    "    3. 외곽선 근사화\n",
    "    4. 너무 작은 객체와 컨벡스가 아닌 객체 제외\n",
    "    5. 꼭지점 개수 확인\n",
    "        1) 삼각형, 사각형 검출\n",
    "        2) 원 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8e19b",
   "metadata": {},
   "source": [
    "## 원 판별하기\n",
    "- 정해진 외곽선 길이에 대한 넓이 비율이 가장 큰 형태가 원 -> 도형의 넓이(A)와 외곽선 길이(P)의 비율을 검사\n",
    "- 4파이와 p의 2승분의 A 값이 1에 가까울수록 원으로 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88732af0",
   "metadata": {},
   "source": [
    "length = cv2.arcLength(pts, True)\n",
    "\n",
    "area = cv2.contourArea(pts)\n",
    "\n",
    "ratio = 4. * math.pi * area / (length * length)\n",
    "\n",
    "if ratio > 0.85:\n",
    "\n",
    "setLabel(img, pts, 'CIR') # 원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aabd50",
   "metadata": {},
   "source": [
    "## 다각형 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c0664",
   "metadata": {},
   "source": [
    "img = cv2.imread('polygon.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, img_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for pts in contours:\n",
    "    \n",
    "    if cv2.contourArea(pts) < 400: - 너무 작으면 무시\n",
    "        continue\n",
    "\n",
    "    approx = cv2.approxPolyDP(pts, cv2.arcLength(pts, True)*0.02, True)\n",
    "    vtc = len(approx)\n",
    "\n",
    "    if vtc == 3:\n",
    "        setLabel(img, pts, 'TRI') - 삼각형\n",
    "    elif vtc == 4:\n",
    "        setLabel(img, pts, 'RECT') - 사각형\n",
    "    else:\n",
    "        ... - 원 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "\n",
    "def setLabel(img, pts, label):\n",
    "    (x, y, w, h) = cv2.boundingRect(pts)\n",
    "    pt1 = (x, y)\n",
    "    pt2 = (x + w, y + h)\n",
    "    cv2.rectangle(img, pt1, pt2, (0, 0, 255), 1)\n",
    "    cv2.putText(img, label, pt1, cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255))\n",
    "\n",
    "def main():\n",
    "    img = cv2.imread('polygon.bmp', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if img is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for pts in contours:\n",
    "        if cv2.contourArea(pts) < 400: #너무 작으면 무시\n",
    "            continue\n",
    "\n",
    "        approx = cv2.approxPolyDP(pts, cv2.arcLength(pts, True)*0.02, True)\n",
    "        \n",
    "        vtc = len(approx)\n",
    "        \n",
    "        if vtc == 3:\n",
    "            setLabel(img, pts, 'TRI')\n",
    "        elif vtc == 4:\n",
    "            setLabel(img, pts, 'RECT')\n",
    "        else:\n",
    "            length = cv2.arcLength(pts, True)\n",
    "            area = cv2.contourArea(pts)\n",
    "            ratio = 4. * math.pi * area / (length * length)\n",
    "\n",
    "            if ratio > 0.85:\n",
    "                setLabel(img, pts, 'CIR')\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d69c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
